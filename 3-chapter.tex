\newpage
\section{\Large Применение методов машинного обучения для классификации данных компьютерного моделирования}
Работа получившейся программы была протестирована на тестовом наборе данных из общей выборки(рисунок~\ref{ris:data_example}). В данной главе расмотрен анализ данных для классификации и этапы работы с разработанной программой.

\subsection{Показатели информативности диагностики}
Для правильной оценки результатов диагностики существует несколько показателей информативности, которые расчитываются после каждого эксперимента. Одними из интересных для текущей задачи показателями являются чувствительность~\eqref{eq:senseq} и специфичность~\eqref{eq:speceq}.
\par
\begin{equation}\label{eq:senseq}
Se = \frac{TP}{TP + FN},
\end{equation}
где $TP$ -- количество истинно положительных результатов, $FN$ -- количество ложноотрицательных результатов~\cite{pokazaetli}.
\begin{equation}\label{eq:speceq}
Sp = \frac{TN}{TN + FP},
\end{equation}
где $TN$ -- количество истинно отрицательных результатов, $FP$ -- количество ложноположительных результатов~\cite{pokazaetli}.
\par
Другим важным показателем является точность определения классов, которая расчитывается по формуле~\eqref{eq:accuracyeq} как доля правильных ответов алгоритма классификации.
\begin{equation}\label{eq:accuracyeq}
Acc = \frac{TP + TN}{TP + TN + FP + FN},
\end{equation}
где $TP$ -- количество истинно положительных результатов, $TN$ -- количество истинно отрицательных результатов, $FP$ -- количество ложноположительных результатов, $FN$ -- количество ложноотрицательных результатов~\cite{pokazaetli}.

\subsection{Частотный анализ классифицируемых данных}
Перед классификацией температурных данных был проведен частотный анализ для исследования распределения температуры в зависимости от того, в какой точке она была замерена и есть ли у данной модели опухоль. Частотный анализ был произведен с помощью библиотеки Pandas, а графическое отображение результатов с помощью Matplotlib. Точки, которые были проанализрованы соответствуют точкам на схеме измерений согласно методу РТМ (рисунок~\ref{ris:rtm-res-scheme}).
\par
Сначала для исследования была взяла точка 0ртм. Результаты исследования представлены в виде диаграммы частот (рисунок~\ref{ris:0rtm}), где верхняя диаграмма -- это здоровые пациенты, а нижняя -- больные.
\imgh{1\linewidth}{0rtm}{Диаграмма частот температур в точке 0ртм. Верхняя диаграмма — здоровые пациенты, нижняя — больные}
\par
Изучив диаграммы, можно заметить, что в данной точке у пациентов чаще встречаются более высокие температуры, нежели у здоровых. Точка 0ртм больше всего подверждена воздействию от опухоли в температурном смысле, так как находится ровно в центре молочной железы.
\par
Следующей для исследования была рассмотрена точка 3ртм, диаграмма частот температур которой представлена на рисунке~\ref{ris:3rtm}. Для данной точки можно наблюдать схожую картину с точкой 0ртм -- тут так же больше значений со средней температурой у больных пациентов, несмотря на то, что эта точка не является центральной.
\imgh{1\linewidth}{3rtm}{Диаграмма частот температур в точке 3ртм. Верхняя диаграмма — здоровые пациенты, нижняя — больные}
\par
Также была рассмотрена точка 7ртм, для которой как видно из диаграммы частот температур (рисунок~\ref{ris:7rtm}) ситуация аналогична с точками 0ртм и 3ртм.
\imgh{1\linewidth}{7rtm}{Диаграмма частот температур в точке 7ртм. Верхняя диаграмма — здоровые пациенты, нижняя — больные}
\par
Так же в качестве эксперимента к модельным данным были добавлены данные реальных пациентов. Данные были получены путем произведения замеров согласно методу РТМ у реальных людей. В выборке реальных данных представлено 168 пациентов, каждый из которых считается изначально здоровым.
\par
Для определения того, насколько модельные данные близки к реальным они были объединены вместе и перемешаны. Затем получившийся набор данных был разбит на два класса -- соответственно модельные и реальные данные. Далее была проведена кластеризация на эти два класса методом k-средних. На рисунке~\ref{ris:clustering_result} представлены графики распределения температурных точек.
\imgh{1\linewidth}{clustering_result}{Графики распределения модельных и реальных данных. График слева -- распределение до кластеризации, справа -- распределение после кластеризации}
Так как заранее было известно к какому из двух классов принадлежат данные, возможным было расчитать точность кластеризации по формуле~\eqref{eq:accuracyeq}. В результате точность кластеризации оказалась равной 68\%, что является неплохим результатом для текущего набора данных.

\subsection{Обучение модели и классификация тестовой выборки}
Первым этапом при работе с программой является загрузка CSV-файла с результатами компьютерного моделирования биотканей. Для этого нужно нажать на кнопку «Выбрать» возле специального поля и выбрать файл на компьютере(рисунок~\ref{ris:upload_data_screenshot}).
\imgh{1\linewidth}{upload_data_screenshot}{Скриншот интерфейса программы при выборе файла с данными для загрузки}
\par
После выбора файла и нажатия на кнопку «Загрузить» файл будет загружен на сервер. Если файл загрузился успешно, то пользователь увидит сообщение как на рисунке~\ref{ris:upload_success}. После загрузки произойдет переинициализация всех используемых в приложении методов библиотеки Scikit-learn и будут очищены файлы с сохраненными моделями.
\imgh{0.65\linewidth}{upload_success}{Сообщение об успешной загрузке файла на сервер}
\par
Также в результате обновления файла были обновлены данные статистических метрик и отрисованы графики (рисунок~\ref{ris:statistics_metrics}). Исходя из этих данных можно сделать первые выводе об используемых при обучении данных. 
\imgh{1\linewidth}{statistics_metrics}{Скриншот графиков со статистическими метриками, вычисленных на основе загруженных данных}
\par
На примере графика с частотным распределением опухолей по точкам можно заметить, что больше всего опухолей расположено в крайних точках с номерами 4 и 8, а меньше всего моделей с опухолями в соседних точках с номерами 6 и 7.
\par
Следующим этапом после загрузки файла следует выбор метода классификации из списка, обучение модели и запуск классификации для тестовой выборки. Для всех перечисленных действий есть отдельные элементы управления (рисунок~\ref{ris:fir_predict_interface}). 
\imgh{1\linewidth}{fir_predict_interface}{Элементы управления для выбора размера тестовой выборки, обучения модели и классификации тестовой выборки}


\addtocontents{toc}{\protect\newpage}

\subsection{Определение класса «Болен»/«Здоров» и точки с опухолью}
Результатом обучения и классификации является круговая диаграмма с точностью определения класса «Болен»/«Здоров». На рисунке~\ref{ris:bayes_accuracy} изображен пример круговой диаграммы с точностью для наивного байесовского классификатора.
\imgh{1\linewidth}{bayes_accuracy}{Круговая диаграмма с точностью классификации для наивного байесовского классификатора}
\par
\subsubsection{Зависимость результата классификации от соотношения обучающей и тестовой выборок}
Точность классификации зависит от многих параметров, в частности от размера обучающей и тестовой выборок. Были проведены эксперименты для разных алгоритмов с различиным процентом тестовой выборки. Результаты данных экспериментов приведены в таблице 1.
\begin{table}[H]
	\begin{flushleft}\hspace{1.25cm}\Large Таблица 1 -- \label{tab:exp2values}Результаты классификации с разным соотношением обучающей и тестовой выборок\end{flushleft}
	\begin{center}
		{\Large
			\begin{tabular}{|c|c|c|}
				\hline
				Алгоритм & Тестовая выборка, \% & Точность классификации, \% \\
				\hline
				\multirow{3}{*}{SVM} & 5 & 62.5 \\
				\cline{2-3}
            	& 10 & 56.3 \\
				\cline{2-3}
            	& 15 & 56.3 \\
				\cline{2-3}
            	& 20 & 57.8 \\
				\hline
				\multirow{3}{*}{\specialcell{k-ближайших \\ соседей}} & 5 & 87.5 \\
				\cline{2-3}
            	& 10 & 65.5 \\
				\cline{2-3}
            	& 15 & 68.8 \\
				\cline{2-3}
            	& 20 & 67.2 \\
            	\hline
				\multirow{3}{*}{Bagging+SVM} & 5 & 62.5 \\
				\cline{2-3}
            	& 10 & 65.6 \\
				\cline{2-3}
            	& 15 & 56.3 \\
				\cline{2-3}
            	& 20 & 59.4 \\
            	\hline
				\multirow{3}{*}{Дерево решений} & 5 & 75 \\
				\cline{2-3}
            	& 10 & 68.8 \\
				\cline{2-3}
            	& 15 & 64.6 \\
				\cline{2-3}
            	& 20 & 70.3 \\
            	\hline
			\end{tabular}
		}
	\end{center}
\end{table}
\par
Для тестовой выборки равной 5\% лучше всего сработал алгоритм k-ближайших соседей с точностью классификации 87.5\%. В экспериментах с тестовой выборкой 10\% и 15\% у всех алгоритмов точность классификации снилизась в среднем на 5-10\%. Исходя из этого можно сделать вывод, что чем меньше процент тестовой выборки, тем хуже точность классификации.
Для тестовой выборки 20\% лучше всего показали себя алгоритмы дерева решений 70.3\% и k-ближайших соседей 67.2\%. Оптимальным вариантом для дальнейшего использования было выбрано значение 20\% для тестовой выборки, так как эксперимент с таким процентом выборки показал себя хуже чем с 5\%, но лучше чем с 10\% и 15\%.

\subsubsection{Зависимость результата классификации от соотношения количества больных и здоровых пациентов в выборке}
На точность классификации значительно может влиять соотношение количества больных и здоровых температурных данных пациентов в выборке. Представленные в предыдущем параграфе результаты были получены для выборки с равным количеством больных и здоровых пациентов. Так же были проведены эксперименты для разного соотношения количества больных и здоровых пациентов, которые представлены в таблице 2.
\begin{table}[H]
	\begin{flushleft}\hspace{1.25cm}\Large Таблица 2 -- \label{tab:exp2values}Результаты классификации с разным соотношением больных и здоровых пациентов в выборках\end{flushleft}
	\begin{center}
		{\Large
			\begin{tabular}{|c|c|c|}
				\hline
				Алгоритм & Количество больных, \% & Точность классификации, \% \\
				\hline
				\multirow{3}{*}{SVM} & 30 & 62 \\
				\cline{2-3}
            	& 50 & 57.8 \\
				\cline{2-3}
            	& 60 & 56.3 \\
				\cline{2-3}
            	& 65 & 56 \\
				\hline
				\multirow{3}{*}{\specialcell{k-ближайших \\ соседей}} & 30 & 73.5 \\
				\cline{2-3}
            	& 50 & 67.2 \\
				\cline{2-3}
            	& 60 & 71.2 \\
				\cline{2-3}
            	& 65 & 54 \\
            	\hline
				\multirow{3}{*}{Bagging+SVM} & 30 & 69.4 \\
				\cline{2-3}
            	& 50 & 59.4 \\
				\cline{2-3}
            	& 60 & 55.8 \\
				\cline{2-3}
            	& 65 & 56 \\
            	\hline
				\multirow{3}{*}{Дерево решений} & 30 & 74.5 \\
				\cline{2-3}
            	& 50 & 70.3 \\
				\cline{2-3}
            	& 60 & 59.6 \\
				\cline{2-3}
            	& 65 & 52 \\
            	\hline
			\end{tabular}
		}
	\end{center}
\end{table}
\par
Исходя из результатов можно заметить, что все алгоритмы показывают лучший результат по точности в выборках с меньшим количеством больных пациентов. Исключением являются эксперименты, где использовался алгоритм k-ближайших соседей, где в трех из четырех случаях точность классификации получилась около 70\%.

\subsubsection{Определение точки с опухолью}
\par
Так же в разработанной программе есть возможность определить класс (диагноз) по данным пациента. После заполнение всех нужных полей и нажатия на кнопку «Диагностировать» буду получены данные о классе и точки, к которой ближе всего расположена опухоль. 
\par
Для определения точки с опухолью используется алгоритм классификации с помощью многослойного персептрона. В обучающую выборку входят только данные больных моделей. В качестве класса используется номер точки, в которой расположена опухоль.
\par
На рисунке~\ref{ris:location_accuracy} приведен пример резульата дианостирования на температурных данных одной из моделей, не попавшей в обучающую выборку. После определения точки с опухолью строится круговая диаграмма с точностью. 
\imgh{1\linewidth}{location_accuracy}{Круговая диаграмма с точностью классификации при определении локализации опухоли}
Как видно на диаграмме -- получилось добиться точности определения класса равной 67.5\%. Возможно этот результат получится улучшить с помощью увеличения объема обучающей выборки или при использовании другого алгоритма классификации.

